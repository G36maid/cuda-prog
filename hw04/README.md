# Introduction to CUDA Parallel Programming Homework Assignment 4
April, 2025

1. Dot-product
Write your own CUDA code for finding the dot-product of 2 real
vectors with N-GPUs, which generalizes the 1-GPU code in
twcp1:/home/cuda_lecture_2025/vecDotProduct/vecDot.cu
Test your code with 2 GPUs, using random vectors of size 40960000
elements generated by the routine RandomInit. Also, determine the
optimal block size and grid size for this problem.

## Notes on CUDA Multi-GPU Programming

### CUDA with Multi-GPUs
A viable way to design CUDA code for multiple GPUs on the same motherboard is to use OpenMP, with one OpenMP thread handling each GPU's operations.

### P2P Memory Copy Process
1. Check for peer-to-peer access between participating GPUs:
   ```cuda
   cudaDeviceCanAccessPeer(&can_access_peer_0_1, gpuid_0, gpuid_1);
   cudaDeviceCanAccessPeer(&can_access_peer_1_0, gpuid_1, gpuid_0);
   ```

2. Enable peer access between participating GPUs:
   ```cuda
   cudaSetDevice(gpuid_0);
   cudaDeviceEnablePeerAccess(gpuid_0, 0);
   cudaSetDevice(gpuid_1);
   cudaDeviceEnablePeerAccess(gpuid_1, 0);
   ```

3. Perform P2P memory copy:
   ```cuda
   cudaMemcpy(gpu1_buf, gpu0_buf, buf_size, cudaMemcpyDeviceToDevice)
   ```

4. Shutdown P2P at the end:
   ```cuda
   cudaSetDevice(gpuid_0);
   cudaDeviceDisablePeerAccess(gpuid_0, 0);
   cudaSetDevice(gpuid_1);
   cudaDeviceDisablePeerAccess(gpuid_1, 0);
   ```

### P2P Direct Access Implementation

#### Initial Setup
1. P2P initialization:
   ```cuda
   cudaDeviceCanAccessPeer(&can_access_peer_0_1, gpuid_0, gpuid_1);
   cudaDeviceCanAccessPeer(&can_access_peer_1_0, gpuid_1, gpuid_0);
   cudaSetDevice(gpuid_0);
   cudaDeviceEnablePeerAccess(gpuid_0, 0);
   cudaSetDevice(gpuid_1);
   cudaDeviceEnablePeerAccess(gpuid_1, 0);
   ```

2. After initialization, any GPU can read/write data in the memory of participating GPUs:
   ```cuda
   cudaSetDevice(gpuid_0);
   SimpleKernel<<<blocks, threads>>>(gpu0_buf, gpu1_buf);
   cudaSetDevice(gpuid_1);
   SimpleKernel<<<blocks, threads>>>(gpu1_buf, gpu0_buf);
   ```

#### Example Usage
```cuda
cudaSetDevice(gpuid_0);
SimpleKernel<<<blocks, threads>>>(gpu0_buf, gpu1_buf); // write to gpu1
cudaSetDevice(gpuid_0);
SimpleKernel<<<blocks, threads>>>(gpu1_buf, gpu0_buf); // read from gpu1
cudaSetDevice(gpuid_1);
SimpleKernel<<<blocks, threads>>>(gpu0_buf, gpu1_buf); // read from gpu0
cudaSetDevice(gpuid_1);
SimpleKernel<<<blocks, threads>>>(gpu1_buf, gpu0_buf); // write to gpu0

__global__ void SimpleKernel(float *src, float *dst)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    dst[idx] = src[idx];
}
```

3. Remember to shutdown P2P access when finished (as shown in step 4 of P2P Memory Copy Process)

## Submission Guidelines
As usual, your homework report should include your source codes,
results, and discussions (without *.exe files). The discussion file should
be prepared with a typesetting system, e.g., LaTeX, Word, etc., and it
is converted to a PDF file. All files should be zipped into one gzipped
tar file, with a file name containing your student number and the
problem set number (e.g., r05202043_ps4.tar.gz). Please send your
homework with the title “your_student_number_HW4” to
twchiu@phys.ntu.edu.tw before 17:00, June 11, 2025 (deadline for all
problem sets).
