# Introduction to CUDA Parallel Programming Homework Assignment 4
April, 2025

## Problem Statement
Write your own CUDA code for finding the dot-product of 2 real vectors with N-GPUs, which generalizes the 1-GPU code in twcp1:/home/cuda_lecture_2025/vecDotProduct/vecDot.cu. Test your code with 2 GPUs, using random vectors of size 40960000 elements generated by the routine RandomInit. Also, determine the optimal block size and grid size for this problem.

## Implementation Details

### Multi-GPU Architecture
- Uses OpenMP to manage 2 GPUs concurrently
- Enables P2P access between GPUs for efficient data transfer
- Each GPU processes half of the input vectors (20.48M elements each)
- Results combined through final reduction on host

### Performance Analysis

#### Configuration Testing Results
- Vector Size: 40960000 (41.0M elements)
- CPU Baseline: 95.142 ms (0.86 GFLOPS)

Top Configurations by Block Size:
```
Block   Grid   KTime(ms)   GFLOPS    RelError
-----------------------------------------
  32    256     1.204      68.06    2.06e-07
  64    256     1.071      76.49    4.27e-07
 128    156     1.066      76.84    1.01e-06
 256     78     1.060      77.25    8.05e-07
 512    157     1.050      78.02    1.70e-07
1024     39     1.064      76.99    7.00e-07
```

#### Optimal Configuration Found
- Block Size: 512 threads/block
- Grid Size: 157 blocks/GPU
- Kernel Time: 1.050 ms
- GFLOPS: 78.02
- Relative Error: 1.70e-07
- Total Speedup vs CPU: 2.97x

### Performance Analysis

1. **Block Size Impact**
   - Small blocks (<128): Lower performance due to underutilization
   - Medium blocks (128-512): Best performance, optimal occupancy
   - Large blocks (1024): Reduced performance due to resource constraints

2. **Grid Size Correlation**
   - Optimal grid size decreases with increasing block size
   - Best performance when total threads (Block × Grid) ≈ 80K per GPU
   - Too many blocks increase overhead
   - Too few blocks reduce parallelism

3. **Memory Transfer Impact**
   - Input Transfer: ~16 ms
   - Kernel Execution: ~1 ms
   - Output Transfer: ~15 ms
   - Memory transfers dominate total execution time

4. **Numerical Accuracy**
   - Relative errors consistently below 1e-6
   - Best configurations maintain accuracy while maximizing performance
   - No significant accuracy variation across block sizes

### Conclusions

1. **Performance Optimization**
   - Block size of 512 provides best balance of parallelism and resource usage
   - Grid size of 157 ensures sufficient work distribution
   - Memory transfers are the main performance bottleneck
   - Achieved 78.02 GFLOPS with optimal configuration

2. **Scalability**
   - 2-GPU implementation shows near-linear scaling for computation
   - Memory transfer overhead limits total speedup
   - Further optimization possible through asynchronous transfers

## Submission Guidelines
Your homework report should include your source codes, results, and discussions (without *.exe files). The discussion file should be prepared with a typesetting system, e.g., LaTeX, Word, etc., and it is converted to a PDF file. All files should be zipped into one gzipped tar file, with a file name containing your student number and the problem set number (e.g., r05202043_ps4.tar.gz). Please send your homework with the title "your_student_number_HW4" to twchiu@phys.ntu.edu.tw before 17:00, June 11, 2025 (deadline for all problem sets).